---
title: artificial Intelligence Act
id: 20230321194418
type: organisation
tags:
  - droit
  - Union Européenne
  - 
---

L'Artificial Intelligence Act (AIA) est un cadre législatif proposé par la Commission européenne en avril 2021 pour réglementer et superviser les applications de l'intelligence artificielle (IA) au sein de l'Union européenne (UE). Voici une fiche explicative des éléments clés de l'AIA :

1.  Objectif : L'AIA vise à garantir un niveau élevé de protection de la vie privée, des consommateurs, des droits de l'homme et des libertés fondamentales pour les citoyens de l'UE. Il encourage également l'innovation et la compétitivité des entreprises européennes en fournissant un cadre réglementaire clair et harmonisé pour le développement et l'application de l'IA.
    
2.  Champ d'application : L'AIA s'applique aux fournisseurs, utilisateurs et importateurs d'IA au sein de l'UE, ainsi qu'aux fournisseurs et importateurs situés en dehors de l'UE, dont les systèmes d'IA sont utilisés dans l'UE.
    
3.  Catégories de risques : L'AIA établit une classification des applications d'IA en fonction des risques potentiels qu'elles présentent pour les droits fondamentaux et la sécurité :
    

* Risque inacceptable : Les applications d'IA présentant un risque inacceptable pour les droits fondamentaux et la sécurité publique sont interdites. Cela inclut les systèmes de manipulation du comportement humain, les systèmes de notation sociale généralisée et les applications de surveillance en temps réel, entre autres.
    
* Risque élevé : Les applications d'IA présentant un risque élevé sont soumises à des exigences réglementaires strictes en matière de transparence, de responsabilité, de sécurité et de protection des données.
    
* Risque limité : Les applications d'IA présentant un risque limité, telles que les chatbots, doivent respecter certaines obligations en matière de transparence.
    
* Risque minimal : Les applications d'IA présentant un risque minimal ne sont pas soumises à des exigences spécifiques.
    

4.  Exigences réglementaires : Les applications d'IA à haut risque doivent se conformer aux exigences suivantes :

* Qualité des données : Les fournisseurs d'IA doivent s'assurer que les données utilisées pour entraîner, valider et tester les systèmes d'IA sont de haute qualité, sans biais discriminatoires.
    
* Documentation : Les fournisseurs d'IA doivent documenter et fournir des informations détaillées sur les systèmes d'IA, leur fonctionnement, leurs objectifs, leurs limites et leur impact sur les droits fondamentaux.
    
* Transparence : Les utilisateurs d'IA doivent être informés lorsqu'ils interagissent avec un système d'IA, et les informations sur la logique et les paramètres de fonctionnement de l'IA doivent être accessibles.
    
* Responsabilité humaine : Les décisions prises par les systèmes d'IA à haut risque doivent être supervisées et vérifiées par des humains.
    
* Sécurité et robustesse : Les systèmes d'IA doivent être sécurisés et résistants aux attaques et aux erreurs, et les fournisseurs d'IA doivent mettre en place des mécanismes de contrôle et de surveillance appropriés.


#GPT4 